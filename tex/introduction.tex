\noindent
The traditional business industry used to be pretty much limited on the scope of both quality and quantity of the presented services because of the narrow amount of the demand and resources. However, after 4 stages of the industrial revolutions more specifically the latter, the capacity of the services disruptively expanded and electronic devices and particularly internet and following that data came to the play. As Online businesses and their services got more publicized the size of data generated by electronic devices and internet users grew bigger and bigger as the volume of data gets nearly doubled every four years \cite{statista} and this is going to get accelerated even more in the future. This data is assumed one of the most valuable assets of the business as it tells the story of the wins and losses and benefits and drawbacks. By going deep into the data combining them and inferring the coherence and utilizing them as the feed of new policies in the flow of the industries, the investment of handling and storing the data will eventually pay off and can take the business as far as it can get in the industry rivalry. If the volume of data is small and manageable considering the current existing hardware, implementing the calculations on the data-set is not a big deal but as soon as the amount of data increases, getting the favorable results from the data gets almost infeasible in the precise time window which is crucial as in most of the cases data has a crucial expiration date.

To convert the data into more useful form multiple layers of algorithms and processes is needed to be implemented on the raw data. For example, if the data is organized and stored in a relational database, the fields from different tables might need to be selected, combined, counted, aggregated, grouped, etc. this type of operations normally is done using SQL (structured query language). 

For example, if we assume that we have a table of the sales of a company which consists of the invoice number, date, sales person ID, product number and number of sold items and also a table for the products containing product ID and the price and in another table we have the information of the sales persons of the company by joining these three tables and grouping by the sales person ID and summing the items prices multiplied by the amount sold and finally sorting the result in descending order, we will have a list of sales persons and the total value of their sales and through that we can analyze the performance of the sale persons in a business. Or in our case, by implementing the sentiment analysis which analyzes, identifies, extracts, and quantifies current states and individual opinions \cite{sentiment_2022} of the customers towards a specific product, valuable information can be derived from the data by combining the SQL queries, particular algorithms alongside with customer reviews sentiment analysis. As far as the volume of data is massive, implementing the necessary processes on the data would demand substantial amount of hardware and time. In fact, after the volume of data exceeds a limit implementing the process on a single computer within a promising period is not feasible. This is exactly where frames like Hadoop and Spark come to the picture.